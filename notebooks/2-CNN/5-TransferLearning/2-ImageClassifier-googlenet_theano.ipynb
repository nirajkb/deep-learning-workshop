{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Purposing a Pretrained Network\n",
    "\n",
    "Since a large CNN is very time-consuming to train (even on a GPU), and requires huge amounts of data, is there any way to use a pre-calculated one instead of retraining the whole thing from scratch?\n",
    "\n",
    "This notebook shows how this can be done.  And it works surprisingly well.\n",
    "\n",
    "\n",
    "##  How do we classify images with untrained classes?\n",
    "\n",
    "This notebook extracts a vector representation of a set of images using the GoogLeNet CNN pretrained on ImageNet.  It then builds a 'simple SVM classifier', allowing new images can be classified directly.  No retraining of the original CNN is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "CLASS_DIR='./images/cars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for building the GoogLeNet model with Lasagne and preprocessing the images are defined in ```model.googlenet```.\n",
    "\n",
    "Build the model and select layers we need - the features are taken from the final network layer, before the softmax nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.imagenet_theano import googlenet\n",
    "\n",
    "cnn_layers = googlenet.build_model()\n",
    "cnn_input_var = cnn_layers['input'].input_var\n",
    "cnn_feature_layer = cnn_layers['loss3/classifier']\n",
    "cnn_output_layer = cnn_layers['prob']\n",
    "\n",
    "get_cnn_features = theano.function([cnn_input_var], lasagne.layers.get_output(cnn_feature_layer))\n",
    "\n",
    "print(\"GoogLeNet Model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained weights into the network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request \n",
    "\n",
    "imagenet_theano = './data/imagenet_theano' \n",
    "googlenet_pkl = imagenet_theano+'/blvc_googlenet.pkl'\n",
    "\n",
    "if not os.path.isfile(googlenet_pkl):\n",
    "    if not os.path.exists(imagenet_theano):\n",
    "        os.makedirs(imagenet_theano)\n",
    "    print(\"Downloading GoogLeNet parameter file\")\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/blvc_googlenet.pkl', \n",
    "        googlenet_pkl)\n",
    "\n",
    "params = pickle.load(open(googlenet_pkl, 'rb'), encoding='iso-8859-1')\n",
    "\n",
    "model_param_values = params['param values']\n",
    "imagenet_classes = params['synset words']\n",
    "\n",
    "lasagne.layers.set_all_param_values(cnn_output_layer, model_param_values)\n",
    "\n",
    "print(\"Loaded GoogLeNet params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Network to create 'features' for the training images\n",
    "\n",
    "Now go through the input images and feature-ize them according to the pretrained network.\n",
    "\n",
    "NB: The pretraining was done on ImageNet - there wasn't anything specific to the recognition task we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "classes = sorted( [ d for d in os.listdir(CLASS_DIR) if os.path.isdir(\"%s/%s\" % (CLASS_DIR, d)) ] )\n",
    "classes # Sorted for for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = dict(f=[], features=[], target=[])\n",
    "\n",
    "t0 = time.time()\n",
    "for class_i,d in enumerate(classes):\n",
    "    for f in os.listdir(\"%s/%s\" % (CLASS_DIR, d,)):\n",
    "        filepath = '%s/%s/%s' % (CLASS_DIR,d,f,)\n",
    "        if os.path.isdir(filepath): continue\n",
    "        im = plt.imread(filepath)\n",
    "        rawim, cnn_im = googlenet.prep_image(im)\n",
    "\n",
    "        prob = get_cnn_features(cnn_im)\n",
    "\n",
    "        train['f'].append(filepath)\n",
    "        train['features'].append(prob[0])\n",
    "        train['target'].append( class_i )\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(rawim.astype('uint8'))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.text(320, 50, '{}'.format(f), fontsize=14)\n",
    "        plt.text(320, 80, 'Train as class \"{}\"'.format(d), fontsize=12)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(train),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build an SVM model over the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(train['features'], train['target']) # learn from the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use the SVM model to classify the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image_files = [f for f in os.listdir(CLASS_DIR) if not os.path.isdir(\"%s/%s\" % (CLASS_DIR, f))]\n",
    "\n",
    "t0 = time.time()\n",
    "for f in sorted(test_image_files):\n",
    "    im = plt.imread('%s/%s' % (CLASS_DIR,f,))\n",
    "    rawim, cnn_im = googlenet.prep_image(im)\n",
    "        \n",
    "    prob = get_cnn_features(cnn_im)\n",
    "\n",
    "    prediction_i = classifier.predict([ prob[0] ])\n",
    "    decision     = classifier.decision_function([ prob[0] ])\n",
    "                       \n",
    "    plt.figure()\n",
    "    plt.imshow(rawim.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "                \n",
    "    prediction = classes[ prediction_i[0] ]\n",
    "                       \n",
    "    plt.text(350, 50, '{} : Distance from boundary = {:5.2f}'.format(prediction, decision[0]), fontsize=20)\n",
    "    plt.text(350, 75, '{}'.format(f), fontsize=14)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(test_image_files),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise : Try your own ideas\n",
    "\n",
    "The whole training regime here is based on the way the image directories are structured.  So building your own example shouldn't be very difficult.\n",
    "\n",
    "Suppose you wanted to classify pianos into Upright and Grand : \n",
    "\n",
    "*  Create a ```pianos``` directory and point the ```CLASS_DIR``` variable at it\n",
    "*  Within the ```pianos``` directory, create subdirectories for each of the classes (i.e. ```Upright``` and ```Grand```).  The directory names will be used as the class labels\n",
    "*  Inside the class directories, put a 'bunch' of positive examples of the respective classes - these can be images in any reasonable format, of any size (above 224x224).\n",
    "   +  The images will be automatically resized so that their smallest dimension is 224, and then a square 'crop' area taken from their centers (since ImageNet networks are typically tuned to answering on 224x224 images)\n",
    "*  Test images should be put in the ```pianos``` directory itelf (which is logical, since we don't *know* their classes yet)\n",
    "\n",
    "Finally, re-run everything - checking that the training images are read in correctly, that there are no errors along the way, and that (finally) the class predictions on the test set come out as expected.\n",
    "\n",
    "If/when it works - please let everyone know : We can add that as an example for next time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}